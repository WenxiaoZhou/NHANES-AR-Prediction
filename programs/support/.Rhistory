# ==========================================================
# ğŸ“¦ Load Required Libraries
# ==========================================================
library(readxl)
library(dplyr)
library(tidyr)
library(ggplot2)
# ==========================================================
# ğŸ“ Step 1: Read and Reshape Data
# ==========================================================
# Adjust the path to your actual file location:
data <- read_excel("/Users/zhouwenxiao/Desktop/ANLY699/Final Project Related/programs/support/result_models.xlsx")
# Separate metric type (mean / sd) and base metric name
data <- data %>%
mutate(
Metric_type = case_when(
grepl("_mean$", Metric) ~ "mean",
grepl("_sd$", Metric) ~ "sd",
grepl("_median$", Metric) ~ "median",
TRUE ~ "other"
),
Metric_base = gsub("_(mean|median|sd)$", "", Metric)
)
# Keep only mean/sd rows
data_filtered <- data %>%
filter(Metric_type %in% c("mean", "sd")) %>%
select(Metric_base, Metric_type, `Logistic Regression`, `Random Forest`, XGBoost)
# Convert wide â†’ long â†’ wide (mean/sd)
data_long <- data_filtered %>%
pivot_longer(
cols = c(`Logistic Regression`, `Random Forest`, XGBoost),
names_to = "Model",
values_to = "Value"
) %>%
group_by(Metric_base, Metric_type, Model) %>%
summarise(Value = mean(as.numeric(Value), na.rm = TRUE), .groups = "drop") %>%  # safe numeric conversion
pivot_wider(
names_from = Metric_type,
values_from = Value
)
# ==========================================================
# ğŸ§¹ Step 2: Clean and Convert Columns
# ==========================================================
data_long <- data_long %>%
mutate(
mean = as.numeric(mean),
sd   = as.numeric(sd),
Model = factor(Model, levels = c("Logistic Regression", "Random Forest", "XGBoost")),
Metric_base = factor(Metric_base,
levels = c("Accuracy", "Balanced_Accuracy", "Recall",
"Precision", "f1", "rocA"))
) %>%
filter(!is.na(mean))
library(ggplot2)
library(dplyr)
metric_labels <- c(
"Accuracy" = "Accuracy",
"Balanced_Accuracy" = "Balanced Accuracy",
"Recall" = "Recall",
"Precision" = "Precision",
"f1" = "F1 Score",
"rocA" = "ROC-AUC"
)
data_long$Metric_base <- factor(
data_long$Metric_base,
levels = names(metric_labels),
labels = metric_labels
)
model_colors <- c(
"Logistic Regression" = "#E64B35",
"Random Forest" = "#4DAF4A",
"XGBoost" = "#377EB8"
)
ggplot(data_long, aes(x = Metric_base, y = mean, color = Model, group = Model)) +
geom_ribbon(aes(ymin = mean - sd, ymax = mean + sd, fill = Model),
alpha = 0.15, color = NA) +
geom_line(linewidth = 1.3) +
geom_point(size = 3.5) +
geom_text(aes(label = sprintf("%.3f", mean)), vjust = -1.1, size = 3.5, fontface = "bold", show.legend=FALSE) +
scale_color_manual(values = model_colors) +
scale_fill_manual(values = model_colors) +
theme_bw(base_size = 14) +
theme(
legend.position = "top",
legend.title = element_blank(),
panel.grid.minor = element_blank(),
panel.grid.major.x = element_blank(),
axis.text.x = element_text(size = 12, angle = 15, hjust = 1, face = "bold"),
axis.text.y = element_text(size = 12, face = "bold"),
axis.title.x = element_text(size = 13, face = "bold"),
axis.title.y = element_text(size = 13, face = "bold"),
plot.title = element_text(size = 15, face = "bold", hjust = 0.5)
) +
coord_cartesian(ylim = c(0.47, 0.77)) +
labs(
title = "Comparative Performance of Machine Learning Models for AR Prediction",
x = "Performance Metric",
y = "Mean Score (Â± SD)"
)
